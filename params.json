{
  "name": "Nipype preprocessing",
  "tagline": "Nipype preprocessing",
  "body": "# Pipeline\r\n\r\nThis is a workflow that uses Nipype on fMRI data to perform preprocessing. The goals are to 1) build a pipeline that is flexible so that it can work with different datasets and 2) to run the preprocessing in parallel to speed up the process.\r\n\r\n##First we tell python to import the appropriate functions.\r\n\r\n\timport os # system functions\r\n\timport nipype.interfaces.fsl as fsl # fsl\r\n\timport nipype.interfaces.afni as afni # afni\r\n\timport nipype.pipeline.engine as pe # the workflow and node wrappers\r\n\timport nipype.interfaces.io as nio # Input/Output\r\n\timport nipype.interfaces.utility as util # utility\r\n\r\n\tPreliminaries\r\n\tWe need to initialize all variables and paths used in the pipeline.\r\n\t# Name of subjects folder\r\n\r\n\tsubjectsfolder = '/gz_Subjects/'\r\n\t# Location of experiment directory\r\n\r\n\texperiment_dir = '/Volumes/homes/Shafquat/'\r\n\t# MNI Location\r\n\r\n\tMNI_2mm = experiment_dir + 'Template/MYtemplate_2mm.nii'\r\n\r\n\tMNI_3mm = experiment_dir + 'Template/MYtemplate_3mm.nii'\r\n\t# location of data folder\r\n\t# Count all the subfolders within a given directory\r\n\r\n\tsubs = next(os.walk(experiment_dir+subjectsfolder))[1]\r\n\r\n\tsubject_list = [] # Initialize an empty list to store subjects\r\n\r\n\tsession_list = ['Run1', 'Run2', 'Run3', 'Run4', 'Run5'] # list of session identifiers\r\n\r\n\t# Set a last run based on the list of runs\r\n\r\n\tlast_run = session_list[-1] # Make sure to change the hardcoded last_run value within the picklast function below\r\n\t# list of subject identifiers\r\n\r\n\tfor subject in subs:\r\n\r\n\tsubject_list.append(subject)\r\n\toutput_dir = 'OUTPUT_serial' # name of output folder\r\n\r\n\tworking_dir = 'workingdir_firstSteps_serial' # name of working directory\r\n\tnumber_of_slices = 40 # number of slices in volume\r\n\r\n\tTR = 2.0 # time repetition of volume\r\n\r\n\tsmoothing_size = 6 # size of FWHM in mm\r\n\r\n\tnumber_volumes_trim = 8 # size of FWHM in mm\r\n\r\n##Node Specification\r\nThe pipeline has various nodes that are steps for preprocessing. Each node will be intialized here with their parameters. We will be using AFNI, FSL, and ANTs functions for each node.\r\n\r\n\tvolTrim = pe.Node(fsl.ExtractROI(t_min = number_volumes_trim,\r\n\t t_size=-1),\r\n\t name='volTrim')\r\n\r\n\tsliceTiming = pe.Node(fsl.SliceTimer(time_repetition = TR,\r\n\t interleaved = True),\r\n\t name=\"sliceTiming\")\r\n\r\n\tmotionCorrection = pe.Node(afni.Volreg(md1d_file = 'max_disp.1d',\r\n\t oned_file = 'mot_par.1d',\r\n\t zpad = 3,\r\n\t outputtype = 'NIFTI_GZ'),\r\n\t name=\"motionCorrection\")\r\n\r\n\ttstat = pe.Node(afni.TStat(args = '-mean',\r\n\t outputtype = 'NIFTI_GZ'),\r\n\t name=\"tstat\")\r\n\r\n\tmean2anatAnts = pe.Node(ants.Registration(args='--float',\r\n \tmetric=['MI'],\r\n \tmetric_weight=[1.0],\r\n \tshrink_factors=[[8,4,2,1]],\r\n \tsmoothing_sigmas=[[3.0,2.0,1.0,0.0]],\r\n \ttransforms=['Rigid'],\r\n \ttransform_parameters=[(0.1,)],\r\n \tnumber_of_iterations=[[1000,500,250,100]],\r\n\t write_composite_transform = True,\r\n\t convergence_threshold=[1e-06],\r\n\t convergence_window_size=[10],\r\n\t output_transform_prefix='mean2anat_',\r\n\t output_warped_image='output_warped_image.nii.gz'),\r\n\t name='mean2anatAnts')\r\n\r\n\tanat2MNI = pe.Node(ants.Registration(args='--float',\r\n\t metric=['Mattes'] * 2 + [['Mattes', 'CC']],\r\n\t metric_weight=[1] * 2 + [[0.5, 0.5]],\r\n\t radius_or_number_of_bins = [32] * 2 + [[32, 4]],\r\n\t sampling_strategy = ['Regular'] * 2 + [[None, None]],\r\n\t sampling_percentage = [0.3] * 2 + [[None, None]],\r\n\t use_histogram_matching = [False] * 2 + [True],\r\n\t shrink_factors=[[3, 2, 1]] * 2 + [[4, 2, 1]],\r\n\t smoothing_sigmas=[[4, 2, 1]] * 2 + [[1, 0.5, 0]],\r\n\t sigma_units = ['vox'] * 3,\r\n\t transforms=['Rigid', 'Affine', 'SyN'],\r\n\t transform_parameters=[(0.1,),(0.1,), (0.2, 3.0, 0.0)],\r\n\t number_of_iterations=[[10000, 11110, 11110]] * 2 + [[100, 30, 20]],\r\n\t write_composite_transform = True,\r\n\t collapse_output_transforms = True,\r\n\t initial_moving_transform_com = True,\r\n\t convergence_threshold= [1.e-8] * 2 + [-0.01],\r\n\t convergence_window_size=[20] * 2 + [5],\r\n\t use_estimate_learning_rate_once = [True] * 3,\r\n\t winsorize_lower_quantile = 0.005,\r\n\t winsorize_upper_quantile = 0.995,\r\n\t num_threads = 2,\r\n\t output_transform_prefix='anat2MNI_',\r\n \toutput_warped_image='MNI_warped_image.nii.gz'),\r\n\t name='anat2MNI')\r\n\tanat2MNI.plugin_args = {'qsub_args': '-pe orte 4',\r\n\t 'sbatch_args': '--mem=6G -c 4'}\r\n\r\n\tmerge = pe.Node(util.Merge(2), iterfield=['in2'], name='mergexfm')\r\n\r\n\tapplyTransFunc = pe.Node(ants.ApplyTransforms(input_image_type = 3,\r\n\t interpolation = 'BSpline',\r\n\t invert_transform_flags = [False, False],\r\n\t terminal_output = 'file'),\r\n\t iterfield=['input_image', 'transforms'],\r\n\t name='applyTransFunc')\r\n\r\n\trefit = pe.Node(afni.Refit(space='TLRC',\r\n\t terminal_output='file',\r\n\t args= '-view tlrc'),\r\n\t name=\"refit\")\r\n\r\n\tsmooth = pe.Node(afni.BlurInMask(fwhm=6,\r\n\t outputtype='NIFTI_GZ',\r\n\t automask = True),\r\n\t name=\"smooth\")\r\n\r\n##Input/Output Specification\r\nIterate over the subjects and select the required files to perform the preprocessing.\r\n\r\n\t# Functional Workflow\r\n\tpreproc = pe.Workflow(name='preproc')\r\n\tpreproc.base_dir = os.path.join(experiment_dir, working_dir)\r\n\r\n\t# Infosource - a function free node to iterate over the list of subject names\r\n\tinfosource = pe.Node(util.IdentityInterface(fields=['subject_id',\r\n\t'session_id']),\r\n\tname=\"infosource\")\r\n\r\n\tinfosource.iterables = [('subject_id', subject_list),\r\n\t('session_id', session_list)]\r\n\r\n\t# SelectFiles for Input\r\n\ttemplates = {'anat': experiment_dir + subjectsfolder + '{subject_id}/Anatomical/*.nii.gz',\r\n\t 'func': experiment_dir + subjectsfolder + '{subject_id}/{session_id}/{session_id}.nii.gz'}\r\n\r\n\tselectfiles = pe.Node(nio.SelectFiles(templates), name=\"selectfiles\")\r\n\r\n\t# DataSink for Output\r\n\tdatasink = pe.Node(nio.DataSink(base_directory=experiment_dir + output_dir),\r\n\t name=\"datasink\")\r\n\r\n\t# Use the following DataSink output substitutions\r\n\tsubstitutions = [('_subject_id', ''),\r\n\t ('_session_id_', '')]\r\n\tdatasink.inputs.substitutions = substitutions\r\n\r\n\tpreproc.connect([(infosource, datasink, [('subject_id', 'container')])\r\n\t])\r\n\r\n\r\n##Motion Correction Workflow\r\nMotion correction is a little more trickier than other nodes because it requires a target image. The one selected for this pipeline is the last image of the last run. I used ExtractROI and some custom built functions to get this image for each subject.\r\n\r\n\t# Set up an extract node to extract the last volume from the last run\r\n\textract_ref = pe.Node(interface=fsl.ExtractROI(t_size=1),\r\n\tname = 'extractref')\r\n\r\n\t# Pick the last file from the list of files\r\n\tdef picklast(path_to_run):\r\n\t\t import os\r\n\t\t last_run = 'Run5'\r\n\t\t # get path to subject\r\n\t\t subject = os.path.dirname(os.path.dirname(path_to_run))\r\n\t\t selected_run = subject + \"/\" + last_run + \"/\" + last_run + \".nii.gz\"\r\n\t\t return selected_run\r\n\r\n\tpreproc.connect(selectfiles, ('func', picklast), extract_ref, 'in_file')\r\n\r\n\t# Pick the last volume from the given run\r\n\tdef getlastvolume(func):\r\n\t\t from nibabel import load\r\n\t\t funcfile = func\r\n\t\t _,_,_,timepoints = load(funcfile).get_shape()\r\n\r\n\t\t # To return middle volume use (timepoints/2)-1\r\n\t \treturn (timepoints-1)\r\n\r\n\tpreproc.connect(sliceTiming, ('slice_time_corrected_file', getlastvolume), extract_ref, 't_min')\r\n\r\n\t# Take the extracted last volume from the last run and use it as a reference file\r\n\tpreproc.connect([(sliceTiming, motionCorrection, [('slice_time_corrected_file', 'in_file')]),\r\n\t(extract_ref, motionCorrection, [('roi_file', 'basefile')])\r\n\t])\r\n\t# Connect all components of the preprocessing workflow\r\n\t# Connect SelectFiles and DataSink to the workflow\r\n\tpreproc.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\r\n\t('session_id', 'session_id')]),\r\n\t(selectfiles, volTrim, [('func', 'in_file')]),\r\n\t(volTrim, sliceTiming, [('roi_file', 'in_file')]),\r\n\t(volTrim, datasink, [('roi_file', '@trimmed')]),\r\n\t(sliceTiming, datasink, [('slice_time_corrected_file', '@sliced')]),\r\n\t(motionCorrection, datasink, [('out_file', '@motion_correct')]),\r\n\t(motionCorrection, datasink, [('md1d_file', '@motion_correct.@mc_md1d')]),\r\n\t(motionCorrection, datasink, [('oned_file', '@motion_correct.@mc_oned')]),\r\n\t])\r\n\r\n\r\n\r\n##Registration Workflow\r\nThis step maps the motion connected runs to the anatomical images (mean2anatAnts) and the anatomical iamges to the MNI template (anat2MNI)\r\n\r\n\t# Workflow after motion correction\r\n\tpreproc2 = pe.Workflow(name='preproc2')\r\n\tpreproc2.base_dir = os.path.join(experiment_dir, working_dir)\r\n\r\n\t# Infosource - a function free node to iterate over the list of subject names\r\n\tinfosource2 = pe.Node(util.IdentityInterface(fields=['subject_id',\r\n\t'session_id']),\r\n\tname=\"infosource2\")\r\n\tinfosource2.iterables = [('subject_id', subject_list)]\r\n\r\n\t# Select the last run for each subject\r\n\ttemplates2 = {'func2': experiment_dir + 'OUTPUT/{subject_id}/' + last_run + '_{subject_id}/' + last_run + '_roi_st_volreg.nii.gz',\r\n\t'anatomical': experiment_dir + subjectsfolder + '{subject_id}/Anatomical/*.nii.gz',\r\n\t'MNI': MNI_2mm}\r\n\tselectfiles2 = pe.Node(nio.SelectFiles(templates2), name=\"selectfiles2\")\r\n\r\n\t# DataSink\r\n\tdatasink2 = pe.Node(nio.DataSink(base_directory=experiment_dir + output_dir),\r\n\tname=\"datasink2\")\r\n\r\n\t# Use the following DataSink output substitutions\r\n\tsubstitutions = [('_subject_id_', '')]\r\n\tdatasink2.inputs.substitutions = substitutions\r\n\r\n\tpreproc2.connect([(infosource2, datasink2, [('subject_id', 'container')])\r\n\t])\r\n\r\n\t# Set up a extract node for the last run after motion control and get the mean\r\n\tpreproc2.connect([(infosource2, selectfiles2, [('subject_id', 'subject_id')]),\r\n\t(selectfiles2, tstat, [('func2', 'in_file')]),\r\n\t(tstat, datasink2, [('out_file', '@tstat')]),\r\n\t(selectfiles2, mean2anatAnts, [('anatomical', 'fixed_image')]),\r\n\t(tstat, mean2anatAnts, [('out_file', 'moving_image')]),\r\n\t(mean2anatAnts, datasink2, [('warped_image', '@mean2anat')]),\r\n\t(mean2anatAnts, datasink2, [('composite_transform', '@mean2anatMatrix_Composites')])\r\n\t])\r\n\r\n\t# Set up a extract node for the Anat to MNI template\r\n\tpreproc2.connect([(selectfiles2, anat2MNI, [('MNI', 'fixed_image')]),\r\n\t(selectfiles2, anat2MNI, [('anatomical', 'moving_image')]),\r\n\t(anat2MNI, datasink2, [('warped_image', '@MNI_warped')]),\r\n\t(anat2MNI, datasink2, [('composite_transform', '@MNI_warpedMatrix')])\r\n\t])\r\n\r\n##Normalization Workflow\r\nThe final workflow normalizes the motion corrected images based on the registered composite matricies.\r\n\r\n\t# Normalization Workflow\r\n\tpreprocReg = pe.Workflow(name='preprocRegister')\r\n\r\n\tpreprocReg.base_dir = os.path.join(experiment_dir, working_dir)\r\n\t# Infosource - a function free node to iterate over the list of subject names\r\n\tinfosourceReg = pe.Node(util.IdentityInterface(fields=['subject_id',\r\n\t'session_id']),\r\n\tname=\"infosourceReg\")\r\n\r\n\tinfosourceReg.iterables = [('subject_id', subject_list),\r\n\t('session_id', session_list)]\r\n\r\n\t# secifying files for select files\r\n\ttemplatesReg = {'mean2anatMatrix': experiment_dir + 'OUTPUT/{subject_id}/mean2anat_Composite.h5',\r\n\t'MNI_warpedMatrix': experiment_dir + 'OUTPUT/{subject_id}/anat2MNI_Composite.h5',\r\n\t'MNI': MNI_3mm,\r\n\t'func_mc': experiment_dir + 'OUTPUT/{subject_id}/{session_id}_{subject_id}/{session_id}_roi_st_volreg.nii.gz'}\r\n\r\n\tselectfilesReg = pe.Node(nio.SelectFiles(templatesReg), name=\"selectfilesReg\")\r\n\r\n\t# DataSink\r\n\tdatasinkReg = pe.Node(nio.DataSink(base_directory=experiment_dir + output_dir),\r\n\tname=\"datasinkReg\")\r\n\tpreprocReg.connect([(infosourceReg, datasinkReg, [('subject_id', 'container')])\r\n\t])\r\n\r\n\t# Use the following DataSink output substitutions\r\n\tsubstitutions = [('_subject_id', ''),\r\n\t('_session_id_', '')]\r\n\tdatasinkReg.inputs.substitutions = substitutions\r\n\r\n\tpreprocReg.connect([(infosourceReg, selectfilesReg, [('subject_id', 'subject_id'),\r\n\t('session_id', 'session_id')]),\r\n\t(selectfilesReg, merge, [('MNI_warpedMatrix', 'in2')]),\r\n\t(selectfilesReg, merge, [('mean2anatMatrix', 'in1')]),\r\n\t(merge, applyTransFunc, [('out', 'transforms')]),\r\n\t(selectfilesReg, applyTransFunc, [('func_mc', 'input_image')]),\r\n\t(selectfilesReg, applyTransFunc, [('MNI', 'reference_image')]),\r\n\t(applyTransFunc, refit, [('output_image', 'in_file')]),\r\n\t(refit, smooth, [('out_file', 'in_file')]),\r\n\t(applyTransFunc, datasinkReg, [('output_image', '@warpedfunc')]),\r\n\t(refit, datasinkReg, [('out_file', '@refitted')]),\r\n\t(smooth, datasinkReg, [('out_file', '@completed_file')]),\r\n\t])\r\n\r\n##Run, Forrest, Run!\r\nThe final step is to run the workflows and output graphs of how the pipeline is connected\r\n\r\n\t# Write graphs to visualize the workflows\r\n\tpreproc.write_graph(graph2use='colored', simple_form=True)\r\n\tpreproc2.write_graph(graph2use='colored', simple_form=True)\r\n\tpreprocReg.write_graph(graph2use='colored', simple_form=True)\r\n\r\n\t# Run the Nodes\r\n\t# Motion Correciton Workflow\r\n\tpreproc.run('MultiProc', plugin_args={'n_procs': 1})\r\n\t# Calculate Composite Transform for image normalization Workflow\r\n\tpreproc2.run('MultiProc', plugin_args={'n_procs': 1})\r\n\t# Applying Composite Transform and Spatial Smoothing Workflow\r\n\tpreprocReg.run('MultiProc', plugin_args={'n_procs': 1})\r\n\r\n# Output Files\r\n\r\n##Subject Level\r\n\r\n* Run5_roi_st_volreg_tstat.nii.gz _Functional mean last run_\r\n* mean2anat_Composite.h5 _Functional mean last run to Anatomical transform matrix_\r\n* anat2MNI_Composite.h5 _Anatomical to MNI transform matrix_\r\n* MNI_warped_image.nii.gz _Anatomical to MNI warped image_\r\n* output_warped_image.nii.gz _Functional mean last run to Anatomical warped image_\r\n\r\n##Within each run (X = 1,2,3,4,5)\r\n\r\n* max_disp.1d _Max displacement (mm) for each volume after motion correction_\r\n* mot_par.1d _6 degree displacement after motion correction_\r\n* RunX_roi.nii.gz _Image after removing first few timepoints_\r\n* RunX_roi_st.nii.gz _Image after slice timing_\r\n* RunX_roi_st_volreg.nii.gz _Image after motion correction_\r\n* RunX_roi_st_volreg_trans.nii.gz _Warped image after refit to TLRC space_\r\n* RunX_roi_st_volreg_trans_blur.nii.gz _Spacially smoothed image_",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}